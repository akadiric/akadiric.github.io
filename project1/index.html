<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta
			name="viewport"
			content="width=device-width, initial-scale=1.0"
		/>
		<title>Gesture-Based Interface</title>
		<link
			rel="stylesheet"
			href="/style.css"
		/>
		<link
			rel="stylesheet"
			href="/header.css"
		/>
		<link
			rel="stylesheet"
			href="/single.css"
		/>
		<link
			rel="preconnect"
			href="https://fonts.googleapis.com"
		/>
		<link
			rel="preconnect"
			href="https://fonts.gstatic.com"
			crossorigin
		/>
		<link
			href="https://fonts.googleapis.com/css2?family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Quicksand:wght@300..700&display=swap"
			rel="stylesheet"
		/>
		<link
			rel="icon"
			type="image/png"
			href="/images/heart.png"
		/>
	</head>
	<body>
		<main>
			<nav class="navbar">
				<a href="/">Home</a>
				<ul class="navbar-links">
					<li>
						<a href="/#About">About</a>
					</li>
					<li>
						<a href="/#Projects">Projects</a>
					</li>
				</ul>
			</nav>

			<section>
				<div class="section-container">
					<h2 class="paragraph-text">
						Sci-Fi to Reality: A Gesture-Based Interface
					</h2>
					<h3>Project Description</h3>
					<p class="paragraph-text">
						We developed a human-computer interface replicating the
						gesture-based video player from Minority Report. This involved
						taking screengrabs from the film to design the UI, creating
						electrical circuits and sewing custom gloves to match those worn by
						the protagonist, modifying a monitor to be transparent for a more
						futuristic look, and building hand recognition software to track
						gestures for video control. We pushed creative boundaries to bring
						this interface to life.
					</p>
				</div>
			</section>
			<section>
				<div class="section-container">
					<h3>Technologies Used</h3>
					<p>
						For the front-end, we used React, Javascript, and CSS to recreate
						the Minority Report videoplay interface. This included key details
						such as multiple timers, video playback and the futuristic blue
						tint. Python was utilized to handle logic and to develop the hand
						and gesture recognition software in order to control video playback.
					</p>
					<p class="paragraph-text">
						<mark>
							Tools and Skills:
							<span style="font-style: italic"
								>React, Javascript, CSS, Python, Hand recognition</span
							>
						</mark>
					</p>
				</div>
			</section>
			<section id="gesture-media">
				<div class="section-container">
					<h3>Media</h3>
					<div class="media-container double-media-container">
						<div>
							<video controls>
								<source
									src="/images/MinorityReportVid.mp4"
									type="video/mp4"
								/>
							</video>
							<p>
								Vid. 1:
								<em> Showcasing video playback control. </em>
							</p>
						</div>
						<div>
							<img
								src="/images/screen.png"
								alt=""
							/>
							<p>Fig. 1: <em> A close-up of the user interface. </em></p>
						</div>
						<div>
							<img
								style="object-position: 0 35%"
								src="/images/monitor.png"
								alt=""
							/>
							<p>Fig. 2: <em> Transparent monitor. </em></p>
						</div>
					</div>
				</div>
			</section>
		</main>
		<footer>
			<blockquote>
				"a STEM graduate? you mean a flower?" - @brotigupta [Tweet]
			</blockquote>
		</footer>
	</body>
</html>
